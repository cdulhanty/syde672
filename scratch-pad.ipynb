{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('mot_benchmark', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mot_benchmark.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fps = 30\n",
    "max_height = 1080\n",
    "max_width = 1920"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset of tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tracks = {}\n",
    "file_names = None\n",
    "file_count = 0\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    if file_names is None: file_names = dirs\n",
    "    if 'gt' in subdir:\n",
    "        print(subdir)\n",
    "        for file in files:\n",
    "            if 'gt.txt' == file:\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                df = pd.read_csv(file_path, names=['frame', 'id', 'bb_left', 'bb_top', \\\n",
    "                                                   'bb_width', 'bb_height', 'conf', 'x', 'y', 'z'])\n",
    "                \n",
    "                fps = data[file_names[file_count]]['fps']\n",
    "                height = data[file_names[file_count]]['height']\n",
    "                width = data[file_names[file_count]]['width']\n",
    "                \n",
    "                file_tracks = []\n",
    "                for id_num in range(1, df['id'].max()+1):\n",
    "                    track_df = df[df['id'] == id_num]\n",
    "                    track = track_df.values[:, np.r_[0:1,2:6]]\n",
    "                    \n",
    "                    if len(track) < 3:  # reject tracks with fewer than three detections\n",
    "                        continue\n",
    "                    \n",
    "                    last_frame_num = 0  # reject track with missing frames\n",
    "                    for i, frame in enumerate(track):\n",
    "                        if last_frame_num == 0:\n",
    "                            last_frame_num = frame[0]\n",
    "                            continue\n",
    "                        else:\n",
    "                            if frame[0] != last_frame_num +1: \n",
    "                                break\n",
    "                            last_frame_num = frame[0]\n",
    "                            \n",
    "                    print(track)\n",
    "                    break\n",
    "                    \n",
    "                    # good track - now normalize based on h & w of image, append fps and add to the list\n",
    "                    np.array([track[:,1] / float(width), track[:,2] / float(height), \n",
    "                                                 track[:,3] / float(width), track[:,4] / float(height),\n",
    "                                                 [fps/max_fps for i in range(len(track))],\n",
    "                                                 [width/max_width for i in range(len(track))],\n",
    "                                                 [height/max_height for i in range(len(track))]])\n",
    "                    \n",
    "                    file_tracks.append(normalized_track.T)\n",
    "                all_tracks[file_names[file_count]] = file_tracks\n",
    "                file_count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "labels = []\n",
    "\n",
    "n_tracks = 0\n",
    "for video in all_tracks.keys():\n",
    "    track_list = all_tracks[video]\n",
    "    for track in track_list:\n",
    "        for i in range(1, len(track)-1):\n",
    "            examples.append(track[:i])\n",
    "            labels.append(track[i][:-3])\n",
    "\n",
    "examples = np.array(examples)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42038 42038\n"
     ]
    }
   ],
   "source": [
    "print(len(examples), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, None, 7)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                5120      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 5,252\n",
      "Trainable params: 5,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(None, 7), name='inputs')\n",
    "x = LSTM(32)(inputs)\n",
    "outputs = Dense(4)(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : training loss: 0.03210819611310924 validation loss: 0.1424982517096214\n",
      "epoch 1 : training loss: 0.02235694718614198 validation loss: 0.11238813692291842\n"
     ]
    }
   ],
   "source": [
    "for i in range(2): # 100 epochs\n",
    "    \n",
    "    training_loss = 0\n",
    "    for example, label in zip(examples[:1000], labels[:1000]):\n",
    "        hist_obj = model.fit(np.expand_dims(example, 0), np.expand_dims(label, 0), verbose=0)\n",
    "        training_loss += hist_obj.history['loss'][0]\n",
    "    \n",
    "    validation_loss = 0\n",
    "    for example, label in zip(examples[1000:1500], labels[1000:1500]):\n",
    "        val_loss = model.evaluate(np.expand_dims(example, 0), np.expand_dims(label, 0), verbose=0)\n",
    "        validation_loss += val_loss\n",
    "\n",
    "    print('epoch', i, ': training loss:', training_loss/float(100), 'validation loss:', validation_loss/float(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('PETS09-S2L1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69293594,  0.49949664, -0.00287014,  0.09591044]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(examples[1084], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = labels[1084]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5494791666666666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
